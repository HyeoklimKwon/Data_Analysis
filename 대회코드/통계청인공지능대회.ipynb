{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code_수정중.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 구글 드라이브 연동\n"
      ],
      "metadata": {
        "id": "x7KmXO3JMXyW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mMwmZGL_e0S",
        "outputId": "7d676efc-c20d-43e0-a8aa-851b8d03b0a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 필요한 라이브러리 설치"
      ],
      "metadata": {
        "id": "K_JLSBg7KTsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "metadata": {
        "id": "82zTtwPkEOZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbfc6064-10f4-497f-85dc-cab3943fa4f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-faitv7v6\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-faitv7v6\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.39-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 7.8 MB/s \n",
            "\u001b[?25hCollecting gluonnlp>=0.6.0\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 54.9 MB/s \n",
            "\u001b[?25hCollecting mxnet>=1.4.0\n",
            "  Downloading mxnet-1.9.0-py3-none-manylinux2014_x86_64.whl (47.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.3 MB 45.1 MB/s \n",
            "\u001b[?25hCollecting onnxruntime==1.8.0\n",
            "  Downloading onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 46.9 MB/s \n",
            "\u001b[?25hCollecting sentencepiece>=0.1.6\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.10.0+cu111)\n",
            "Collecting transformers>=4.8.1\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 46.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (1.21.5)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (3.17.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (0.29.28)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (21.3)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.3) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2021.10.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->kobert==0.2.3) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (3.6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 42.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.63.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.11.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp>=0.6.0->kobert==0.2.3) (3.0.7)\n",
            "Collecting botocore<1.25.0,>=1.24.39\n",
            "  Downloading botocore-1.24.39-py3-none-any.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 49.3 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 58.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.39->boto3->kobert==0.2.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.39->boto3->kobert==0.2.3) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.8.1->kobert==0.2.3) (3.7.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (1.1.0)\n",
            "Building wheels for collected packages: kobert, gluonnlp\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15674 sha256=3707e1d66793a77322f1ac1b279419296824c6103e5405ab50810310a63e30a6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5dx5qiwe/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595741 sha256=7395ff4f84b3a2846b70efbcb165c69bd1cc45d9c65ec6859c1c23d3e86e9039\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n",
            "Successfully built kobert gluonnlp\n",
            "Installing collected packages: urllib3, jmespath, pyyaml, botocore, tokenizers, sacremoses, s3transfer, huggingface-hub, graphviz, transformers, sentencepiece, onnxruntime, mxnet, gluonnlp, boto3, kobert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.21.39 botocore-1.24.39 gluonnlp-0.10.0 graphviz-0.8.4 huggingface-hub-0.5.1 jmespath-1.0.0 kobert-0.2.3 mxnet-1.9.0 onnxruntime-1.8.0 pyyaml-6.0 s3transfer-0.5.2 sacremoses-0.0.49 sentencepiece-0.1.96 tokenizers-0.11.6 transformers-4.18.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKaiqfeQD7ZK",
        "outputId": "96ee1fdb-103d-43a4-b37d-ff112df6c2cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 542 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 56.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터불러오기 "
      ],
      "metadata": {
        "id": "oE29QEF5D-N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "#kobert\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "\n",
        "#transformers\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ],
      "metadata": {
        "id": "-o7KeP8LKqX6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/통계데이터_인공지능_활용대회/1. 실습용자료.txt', sep = \"|\", encoding = \"cp949\")\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/통계데이터_인공지능_활용대회/2. 모델개발용자료.txt', sep = \"|\", encoding = \"cp949\")\n"
      ],
      "metadata": {
        "id": "iJcaY38odO4q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_spread = train_data['digit_3'].value_counts()\n",
        "class_name = train_data['digit_3'].unique()"
      ],
      "metadata": {
        "id": "Pcp415Aohsp7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('클래스 개수는 : ',len(class_name))\n",
        "print('class_name: \\n',class_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtQiQ5vTKQMR",
        "outputId": "f1c6697e-2cdc-4b77-a7ea-27affeb25778"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스 개수는 :  225\n",
            "class_name: \n",
            " [952 472 467 475 872 291 561 107 841 423 102 474 856 529 473 761 911 562\n",
            " 221 961 292 477 969 949 471 551 464 493 259 732 478 912 422 222 855 320\n",
            " 711 465 582 721 863 559 729 141 476 461 452 953 682 339 862 466 281 712\n",
            " 492 752 203 681 901 742 713 592 340 261 463 262 411 163 424 243 521 851\n",
            " 106 421 479 941 902 311 468 204  72 181 662 852 641 239 453 251 103 762\n",
            " 202 151 462 653 233 161 861 101 620 733 104 412 857 134 242 661 426 132\n",
            " 171 751 112 139 701 263 284 162 303 715 942 501 232  71 144 331 383 702\n",
            " 871 759 741 179 241 289 591 763 951 105 869 451 172 739 611 272 271 649\n",
            " 351 302 285 753 111 264 425 201 265 334 639 842 231 205 131 494 581 642\n",
            " 274 764 382 651 283 319 370 333 631  20 602 390  11 743 714 133 108  32\n",
            " 143 716 152 844 381 313 612 212  14 353 360 352 312 273 332 191 282  12\n",
            " 252  31 731 213 301 192 182 495 211  62 511  61 853 502 854 845 512 142\n",
            " 491 304  80 652 843 601 266  51 120]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict = dict(class_spread) # 클래스 개수별 분포"
      ],
      "metadata": {
        "id": "369SbxpvplzK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_dict = dict(sorted(my_dict.items())) # 정렬 \n",
        "print(sorted_dict)\n",
        "\n",
        "number = 11 # 원하는 클래스 \n",
        "print('class {}의 개수는 '.format(number),sorted_dict[number])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpR3cVthp5WC",
        "outputId": "b41d7cff-b2da-4b07-8bd3-09a0b6153941"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{11: 396, 12: 254, 14: 177, 20: 121, 31: 13, 32: 103, 51: 1, 61: 1, 62: 6, 71: 190, 72: 223, 80: 3, 101: 729, 102: 985, 103: 1177, 104: 769, 105: 64, 106: 1353, 107: 9214, 108: 285, 111: 250, 112: 137, 120: 3, 131: 474, 132: 2819, 133: 217, 134: 965, 139: 812, 141: 4421, 142: 66, 143: 304, 144: 626, 151: 865, 152: 514, 161: 335, 162: 1344, 163: 45, 171: 206, 172: 996, 179: 552, 181: 4139, 182: 38, 191: 20, 192: 68, 201: 338, 202: 658, 203: 334, 204: 1643, 205: 56, 211: 39, 212: 156, 213: 118, 221: 803, 222: 4935, 231: 523, 232: 670, 233: 758, 239: 922, 241: 1279, 242: 533, 243: 403, 251: 4156, 252: 33, 259: 12876, 261: 391, 262: 1666, 263: 284, 264: 718, 265: 239, 266: 8, 271: 1484, 272: 1506, 273: 170, 274: 47, 281: 2756, 282: 84, 283: 412, 284: 1338, 285: 580, 289: 354, 291: 4924, 292: 7163, 301: 20, 302: 323, 303: 2407, 304: 22, 311: 732, 312: 93, 313: 106, 319: 101, 320: 3275, 331: 605, 332: 76, 333: 295, 334: 212, 339: 3396, 340: 3380, 351: 660, 352: 67, 353: 29, 360: 147, 370: 436, 381: 704, 382: 371, 383: 568, 390: 29, 411: 3582, 412: 3363, 421: 4724, 422: 5744, 423: 4360, 424: 11152, 425: 559, 426: 1566, 451: 2268, 452: 4696, 453: 471, 461: 2328, 462: 2585, 463: 17873, 464: 18453, 465: 14652, 466: 8154, 467: 12096, 468: 694, 471: 26189, 472: 25668, 473: 9312, 474: 36453, 475: 13031, 476: 7188, 477: 4577, 478: 30566, 479: 9218, 491: 58, 492: 39176, 493: 49115, 494: 2134, 495: 3, 501: 281, 502: 34, 511: 32, 512: 9, 521: 1591, 529: 5605, 551: 12549, 559: 1417, 561: 123703, 562: 49756, 581: 1548, 582: 3771, 591: 1250, 592: 230, 601: 20, 602: 186, 611: 796, 612: 317, 620: 1919, 631: 456, 639: 369, 641: 4113, 642: 165, 649: 1018, 651: 1715, 652: 2, 653: 171, 661: 1211, 662: 1983, 681: 6928, 682: 33212, 701: 1538, 702: 425, 711: 3963, 712: 3128, 713: 3025, 714: 97, 715: 3318, 716: 106, 721: 5513, 729: 1635, 731: 1049, 732: 1743, 733: 2335, 739: 559, 741: 783, 742: 1866, 743: 239, 751: 3712, 752: 2605, 753: 524, 759: 3583, 761: 938, 762: 1948, 763: 1482, 764: 21, 841: 1189, 842: 467, 843: 5, 844: 1267, 845: 37, 851: 3544, 852: 1333, 853: 366, 854: 67, 855: 16862, 856: 23521, 857: 917, 861: 878, 862: 15287, 863: 853, 869: 1198, 871: 2128, 872: 15743, 901: 1465, 902: 3039, 911: 9779, 912: 15468, 941: 1612, 942: 433, 949: 21580, 951: 1508, 952: 12142, 953: 6911, 961: 43040, 969: 13170}\n",
            "class 11의 개수는  396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 불용어 처리 \n"
      ],
      "metadata": {
        "id": "x8dtWg2QLH_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_mod = train_data[['digit_3','text_obj','text_mthd','text_deal']]"
      ],
      "metadata": {
        "id": "SPwzSzncpvVK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_mod = df_mod.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
        "print(df_mod.isnull().values.any()) # Null 값이 존재하는지 확인\n",
        "df_mod = df_mod.fillna(' ') # Nan 값을 빈 string으로 바꿈\n",
        "print(df_mod.isnull().values.any()) # Null 값이 존재하는지 확인\n",
        "# False => nan값이 없다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgdMe3HnLSRA",
        "outputId": "02fbbb6f-d7f4-4ac7-95b5-6302f3c75472"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data x, y 로 나누기\n",
        "x1 = df_mod['text_obj'].astype(str)\n",
        "x2 = df_mod['text_mthd'].astype(str)\n",
        "x3 = df_mod['text_deal'].astype(str)"
      ],
      "metadata": {
        "id": "U2QCnARgi8GN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_1 = ['에서','으로','에게','하여',] # text_obj, text_mthd,\n",
        "remove_2 =['일반','고객'] # text_mthd \n",
        "remove_3 = ['를 통하여','을 갖추고','를통하여'] #  text_mthd\n",
        "for i in range(len(x1)):\n",
        "  # remove 1\n",
        "  if x1.iloc[i][-2::]in remove_1: # text_obj\n",
        "    x1[i]=x1.iloc[i][0:-2]\n",
        "  \n",
        "  if x2.iloc[i][-2::]in remove_1: # text_mthd\n",
        "    x2[i]=x2.iloc[i][0:-2]\n",
        "\n",
        "  # remove 2\n",
        "  if x2.iloc[i][0:2]in remove_2:  # text_mthd\n",
        "    x2[i]=' ' # remove_2 들어가면 제거 \n",
        "    \n",
        "  # remove 3\n",
        "  if x2.iloc[i][-5::]in remove_3: # text_mthd\n",
        "    x2[i]=x1.iloc[i][0:-5]\n",
        "  \n",
        "  if x2.iloc[i][-4::]in remove_3: # text_mthd\n",
        "    x2[i]=x1.iloc[i][0:-4]\n",
        "    \n",
        "  if i % 100000 == 0:\n",
        "    print(i)\n",
        "    \n",
        "    \n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4j6ZcZRix7l",
        "outputId": "b17699f9-3ec8-4543-b486-c66148f0df1d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100000\n",
            "200000\n",
            "300000\n",
            "400000\n",
            "500000\n",
            "600000\n",
            "700000\n",
            "800000\n",
            "900000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x1 + ',' + x2+','+ x3\n",
        "y = df_mod['digit_3']"
      ],
      "metadata": {
        "id": "Ewj75qSIidwy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 이름, 클래스 개수 \n",
        "print(\"class 개수는 \",len(df_mod['digit_3'].unique()), df_mod['digit_3'].unique())\n",
        "class_name = df_mod['digit_3'].unique()\n",
        "# class change (11~969 => 0~225)\n",
        "for idx, class_n in enumerate(class_name):\n",
        "  df_mod.loc[(df_mod['digit_3'] == class_n),'digit_3'] = idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGmppgwuMf35",
        "outputId": "c61b111a-8e37-4bed-b9da-8a6bee98f398"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class 개수는  225 [952 472 467 475 872 291 561 107 841 423 102 474 856 529 473 761 911 562\n",
            " 221 961 292 477 969 949 471 551 464 493 259 732 478 912 422 222 855 320\n",
            " 711 465 582 721 863 559 729 141 476 461 452 953 682 339 862 466 281 712\n",
            " 492 752 203 681 901 742 713 592 340 261 463 262 411 163 424 243 521 851\n",
            " 106 421 479 941 902 311 468 204  72 181 662 852 641 239 453 251 103 762\n",
            " 202 151 462 653 233 161 861 101 620 733 104 412 857 134 242 661 426 132\n",
            " 171 751 112 139 701 263 284 162 303 715 942 501 232  71 144 331 383 702\n",
            " 871 759 741 179 241 289 591 763 951 105 869 451 172 739 611 272 271 649\n",
            " 351 302 285 753 111 264 425 201 265 334 639 842 231 205 131 494 581 642\n",
            " 274 764 382 651 283 319 370 333 631  20 602 390  11 743 714 133 108  32\n",
            " 143 716 152 844 381 313 612 212  14 353 360 352 312 273 332 191 282  12\n",
            " 252  31 731 213 301 192 182 495 211  62 511  61 853 502 854 845 512 142\n",
            " 491 304  80 652 843 601 266  51 120]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = []\n",
        "for q, label in zip(x, y)  :\n",
        "    data = []\n",
        "    data.append(q)\n",
        "    data.append(str(label))\n",
        "\n",
        "    data_list.append(data)"
      ],
      "metadata": {
        "id": "JZT2FsY2Mp51"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A2-M77h-Dl4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 불용어처리 재시도"
      ],
      "metadata": {
        "id": "nuDtQf7aDqaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = \"에서 로 으로 갖추고 일반 대상 . , 등 따라 의해 에 로 위하여 ? 통해 하여 에게 소비 제공 소비자 고객 일반인 을 를 의 하여 해서 요청 가지고 및 두고 받아 받음 서비스\"\n",
        "stop_words = set(stop_words.split(' '))\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z87o_oiNGthE",
        "outputId": "49a7ca46-878b-4fc0-d535-adb71ce2e01e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'위하여', '두고', '가지고', '하여', '갖추고', '소비자', '일반인', '소비', '에', '해서', '.', '의해', '요청', '받음', '에게', '통해', '받아', '등', '고객', '?', '을', '제공', '의', '로', ',', '따라', '대상', '으로', '및', '서비스', '를', '에서', '일반'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from konlpy.tag import Okt"
      ],
      "metadata": {
        "id": "kCUdSVjWG5eU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()"
      ],
      "metadata": {
        "id": "V-XGVjY8HBLO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnt = 0\n",
        "for i in range(len(data_list)):\n",
        "  q = data_list[i][0]\n",
        "  word_tokens = okt.morphs(q)  \n",
        "  result = ' '\n",
        "  for word in word_tokens:\n",
        "    if not word in stop_words:\n",
        "      result += ' ' + word  \n",
        "  data_list[i][0] = result\n",
        "  cnt += 1\n",
        "  if cnt%3000 == 0:\n",
        "    print(cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpn9U5U4Go_9",
        "outputId": "86865155-2b79-4f9d-c9ea-06ca1cb7f699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000\n",
            "6000\n",
            "9000\n",
            "12000\n",
            "15000\n",
            "18000\n",
            "21000\n",
            "24000\n",
            "27000\n",
            "30000\n",
            "33000\n",
            "36000\n",
            "39000\n",
            "42000\n",
            "45000\n",
            "48000\n",
            "51000\n",
            "54000\n",
            "57000\n",
            "60000\n",
            "63000\n",
            "66000\n",
            "69000\n",
            "72000\n",
            "75000\n",
            "78000\n",
            "81000\n",
            "84000\n",
            "87000\n",
            "90000\n",
            "93000\n",
            "96000\n",
            "99000\n",
            "102000\n",
            "105000\n",
            "108000\n",
            "111000\n",
            "114000\n",
            "117000\n",
            "120000\n",
            "123000\n",
            "126000\n",
            "129000\n",
            "132000\n",
            "135000\n",
            "138000\n",
            "141000\n",
            "144000\n",
            "147000\n",
            "150000\n",
            "153000\n",
            "156000\n",
            "159000\n",
            "162000\n",
            "165000\n",
            "168000\n",
            "171000\n",
            "174000\n",
            "177000\n",
            "180000\n",
            "183000\n",
            "186000\n",
            "189000\n",
            "192000\n",
            "195000\n",
            "198000\n",
            "201000\n",
            "204000\n",
            "207000\n",
            "210000\n",
            "213000\n",
            "216000\n",
            "219000\n",
            "222000\n",
            "225000\n",
            "228000\n",
            "231000\n",
            "234000\n",
            "237000\n",
            "240000\n",
            "243000\n",
            "246000\n",
            "249000\n",
            "252000\n",
            "255000\n",
            "258000\n",
            "261000\n",
            "264000\n",
            "267000\n",
            "270000\n",
            "273000\n",
            "276000\n",
            "279000\n",
            "282000\n",
            "285000\n",
            "288000\n",
            "291000\n",
            "294000\n",
            "297000\n",
            "300000\n",
            "303000\n",
            "306000\n",
            "309000\n",
            "312000\n",
            "315000\n",
            "318000\n",
            "321000\n",
            "324000\n",
            "327000\n",
            "330000\n",
            "333000\n",
            "336000\n",
            "339000\n",
            "342000\n",
            "345000\n",
            "348000\n",
            "351000\n",
            "354000\n",
            "357000\n",
            "360000\n",
            "363000\n",
            "366000\n",
            "369000\n",
            "372000\n",
            "375000\n",
            "378000\n",
            "381000\n",
            "384000\n",
            "387000\n",
            "390000\n",
            "393000\n",
            "396000\n",
            "399000\n",
            "402000\n",
            "405000\n",
            "408000\n",
            "411000\n",
            "414000\n",
            "417000\n",
            "420000\n",
            "423000\n",
            "426000\n",
            "429000\n",
            "432000\n",
            "435000\n",
            "438000\n",
            "441000\n",
            "444000\n",
            "447000\n",
            "450000\n",
            "453000\n",
            "456000\n",
            "459000\n",
            "462000\n",
            "465000\n",
            "468000\n",
            "471000\n",
            "474000\n",
            "477000\n",
            "480000\n",
            "483000\n",
            "486000\n",
            "489000\n",
            "492000\n",
            "495000\n",
            "498000\n",
            "501000\n",
            "504000\n",
            "507000\n",
            "510000\n",
            "513000\n",
            "516000\n",
            "519000\n",
            "522000\n",
            "525000\n",
            "528000\n",
            "531000\n",
            "534000\n",
            "537000\n",
            "540000\n",
            "543000\n",
            "546000\n",
            "549000\n",
            "552000\n",
            "555000\n",
            "558000\n",
            "561000\n",
            "564000\n",
            "567000\n",
            "570000\n",
            "573000\n",
            "576000\n",
            "579000\n",
            "582000\n",
            "585000\n",
            "588000\n",
            "591000\n",
            "594000\n",
            "597000\n",
            "600000\n",
            "603000\n",
            "606000\n",
            "609000\n",
            "612000\n",
            "615000\n",
            "618000\n",
            "621000\n",
            "624000\n",
            "627000\n",
            "630000\n",
            "633000\n",
            "636000\n",
            "639000\n",
            "642000\n",
            "645000\n",
            "648000\n",
            "651000\n",
            "654000\n",
            "657000\n",
            "660000\n",
            "663000\n",
            "666000\n",
            "669000\n",
            "672000\n",
            "675000\n",
            "678000\n",
            "681000\n",
            "684000\n",
            "687000\n",
            "690000\n",
            "693000\n",
            "696000\n",
            "699000\n",
            "702000\n",
            "705000\n",
            "708000\n",
            "711000\n",
            "714000\n",
            "717000\n",
            "720000\n",
            "723000\n",
            "726000\n",
            "729000\n",
            "732000\n",
            "735000\n",
            "738000\n",
            "741000\n",
            "744000\n",
            "747000\n",
            "750000\n",
            "753000\n",
            "756000\n",
            "759000\n",
            "762000\n",
            "765000\n",
            "768000\n",
            "771000\n",
            "774000\n",
            "777000\n",
            "780000\n",
            "783000\n",
            "786000\n",
            "789000\n",
            "792000\n",
            "795000\n",
            "798000\n",
            "801000\n",
            "804000\n",
            "807000\n",
            "810000\n",
            "813000\n",
            "816000\n",
            "819000\n",
            "822000\n",
            "825000\n",
            "828000\n",
            "831000\n",
            "834000\n",
            "837000\n",
            "840000\n",
            "843000\n",
            "846000\n",
            "849000\n",
            "852000\n",
            "855000\n",
            "858000\n",
            "861000\n",
            "864000\n",
            "867000\n",
            "870000\n",
            "873000\n",
            "876000\n",
            "879000\n",
            "882000\n",
            "885000\n",
            "888000\n",
            "891000\n",
            "894000\n",
            "897000\n",
            "900000\n",
            "903000\n",
            "906000\n",
            "909000\n",
            "912000\n",
            "915000\n",
            "918000\n",
            "921000\n",
            "924000\n",
            "927000\n",
            "930000\n",
            "933000\n",
            "936000\n",
            "939000\n",
            "942000\n",
            "945000\n",
            "948000\n",
            "951000\n",
            "954000\n",
            "957000\n",
            "960000\n",
            "963000\n",
            "966000\n",
            "969000\n",
            "972000\n",
            "975000\n",
            "978000\n",
            "981000\n",
            "984000\n",
            "987000\n",
            "990000\n",
            "993000\n",
            "996000\n",
            "999000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train data split (Train & Valid)\n"
      ],
      "metadata": {
        "id": "mLeNeBwuMc2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #train & test 데이터로 나누기 7:3\n",
        "from sklearn.model_selection import train_test_split\n",
        "                                                         \n",
        "dataset_Train, dataset_Valid = train_test_split(data_list, test_size=0.3, random_state = 1)\n",
        "print('dataset_Train :',len(dataset_Train))\n",
        "print('dataset_Valid',len(dataset_Valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFoiIAljMya-",
        "outputId": "48751089-fe0c-45dc-c326-35acd318267a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset_Train : 700000\n",
            "dataset_Valid 300000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting parameters\n",
        "max_len = 32 \n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 1  \n",
        "max_grad_norm = 1 \n",
        "log_interval = 200\n",
        "learning_rate =  5e-5 "
      ],
      "metadata": {
        "id": "MEnuXva5NCF8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU 사용\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "#BERT 모델, Vocabulary 불러오기 \n",
        "\n",
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f11wxLOWOEhK",
        "outputId": "fc92a218-0fdf-4a08-bf63-8aa7ae5f0597"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n",
            "/content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUd-XteQNKlw",
        "outputId": "9f0f5f16-0a2a-4526-8c71-de927ccdadc6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  BERTDataset class\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "metadata": {
        "id": "7v6Gf77vM15-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#토큰화\n",
        "\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "data_Train = BERTDataset(dataset_Train, 0, 1, tok, max_len, True, False)\n",
        "data_Valid = BERTDataset(dataset_Valid, 0, 1, tok, max_len, True, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "ngapF8wbNMHQ",
        "outputId": "a9da2ad1-d778-4eff-ad87-606df04b4e82"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6e82c67c095f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBERTSPTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata_Train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdata_Valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_Valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset_Train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader \n",
        "Train_dataloader = torch.utils.data.DataLoader(data_Train, batch_size=batch_size, num_workers=2)\n",
        "Valid_dataloader = torch.utils.data.DataLoader(data_Valid, batch_size=batch_size, num_workers=2)"
      ],
      "metadata": {
        "id": "WxzI4TGINkIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model "
      ],
      "metadata": {
        "id": "tnt3wxdgO1ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=len(class_name),   ##클래스 수 조정##\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "metadata": {
        "id": "2FY5hPSLOWVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT 모델 불러오기\n",
        "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
        "\n",
        "#optimizer와 schedule 설정\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "t_total = len(Train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
        "\n",
        "#정확도 측정을 위한 함수 정의\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc\n",
        "    \n",
        "# train_dataloader"
      ],
      "metadata": {
        "id": "z7_XmqnLOiHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        # token_ids = token_ids.long()\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        # segment_ids = segment_ids.long()\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        # label = label.long()\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    #torch.save(model.state_dict(), '/content/drive/MyDrive/model_0412_km_{}.pth'.format('removemodel_22'))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        # label = label.long()\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
      ],
      "metadata": {
        "id": "gHaFZxcFDFYe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "76894fd2e8af45c687fcdd7321f5f2ee",
            "73981a91a30f460689d5f3cd3f7968fd",
            "afd6d5dab8c6438a9b81e8200e18fc72",
            "dd8e508bde4f46aead02b722d362deaf",
            "f2511b366c004d3dad9dd965e4a9c24c",
            "5d398007f3a54bb1a4de45243b84c295",
            "ed564eb9defd47d0b830e56f09b68e66",
            "bcf27d995ff74de2a4096127470007a2",
            "5f0cb1f402124dca97109a9df659e22f",
            "ec04433f3f04496eaeb198c32ee85a8e",
            "38903786e5a4448a8aecb69368116867",
            "a940bc5ee31741848a8ec702906e461d",
            "347feea0bc904590b624723693311fa3",
            "f86b608ebe954fc5b93e979841a9a044",
            "6aefa35a858a4c568f59ec50bc463180",
            "b0ac2a38403f440ea3dc81e460fca327",
            "aeb39058be7e41a0a2e5377159e848e4",
            "eef6a9ad735b4ff59accc0cd784407ba",
            "a19a1a9c78b74c7b837c0bfc8b9dc42a",
            "4ddc149827f0445eb245b00a9463bb20",
            "93310995343e441aa3a2fdfe4bea90dd",
            "be8fbd7d1fcc4c5ea50bac2bdec459b8"
          ]
        },
        "outputId": "ad9e2f9d-240c-4197-d5a0-a57bcde7491d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10938 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76894fd2e8af45c687fcdd7321f5f2ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 batch id 1 loss 5.685079574584961 train acc 0.0\n",
            "epoch 1 batch id 201 loss 3.9605143070220947 train acc 0.16223569651741293\n",
            "epoch 1 batch id 401 loss 1.594641089439392 train acc 0.42631701995012466\n",
            "epoch 1 batch id 601 loss 0.663910448551178 train acc 0.568609608985025\n",
            "epoch 1 batch id 801 loss 0.7442579865455627 train acc 0.6487398564294632\n",
            "epoch 1 batch id 1001 loss 0.5820630192756653 train acc 0.6992382617382618\n",
            "epoch 1 batch id 1201 loss 0.28422489762306213 train acc 0.7329699208992506\n",
            "epoch 1 batch id 1401 loss 0.5557947754859924 train acc 0.7570596895074947\n",
            "epoch 1 batch id 1601 loss 0.560264527797699 train acc 0.7751893347907558\n",
            "epoch 1 batch id 1801 loss 0.36260679364204407 train acc 0.7900298445308163\n",
            "epoch 1 batch id 2001 loss 0.5623184442520142 train acc 0.8019349700149925\n",
            "epoch 1 batch id 2201 loss 1.0091991424560547 train acc 0.8123367219445706\n",
            "epoch 1 batch id 2401 loss 0.23530274629592896 train acc 0.8211422324031653\n",
            "epoch 1 batch id 2601 loss 0.6551896333694458 train acc 0.8287137158785083\n",
            "epoch 1 batch id 2801 loss 0.3135315775871277 train acc 0.8351816315601571\n",
            "epoch 1 batch id 3001 loss 0.5972272157669067 train acc 0.8406416611129623\n",
            "epoch 1 batch id 3201 loss 0.41437992453575134 train acc 0.8455365510777882\n",
            "epoch 1 batch id 3401 loss 0.38795340061187744 train acc 0.8498281755366068\n",
            "epoch 1 batch id 3601 loss 0.7238437533378601 train acc 0.8535910163843377\n",
            "epoch 1 batch id 3801 loss 0.4320729672908783 train acc 0.8570400881347013\n",
            "epoch 1 batch id 4001 loss 0.6276177167892456 train acc 0.8599022119470132\n",
            "epoch 1 batch id 4201 loss 0.39501237869262695 train acc 0.862900946203285\n",
            "epoch 1 batch id 4401 loss 0.7523612976074219 train acc 0.8654354124062713\n",
            "epoch 1 batch id 4601 loss 0.37533167004585266 train acc 0.8681129102369051\n",
            "epoch 1 batch id 4801 loss 0.16223856806755066 train acc 0.8703362580712352\n",
            "epoch 1 batch id 5001 loss 0.386136919260025 train acc 0.8724505098980204\n",
            "epoch 1 batch id 5201 loss 0.36514291167259216 train acc 0.8744021582388002\n",
            "epoch 1 batch id 5401 loss 0.5660060048103333 train acc 0.8761427281984817\n",
            "epoch 1 batch id 5601 loss 0.326830118894577 train acc 0.8777059900017854\n",
            "epoch 1 batch id 5801 loss 0.36938953399658203 train acc 0.8793042147905533\n",
            "epoch 1 batch id 6001 loss 0.2941751480102539 train acc 0.8809417180469922\n",
            "epoch 1 batch id 6201 loss 0.37353259325027466 train acc 0.8823274471859377\n",
            "epoch 1 batch id 6401 loss 0.41919466853141785 train acc 0.8837364279018903\n",
            "epoch 1 batch id 6601 loss 0.4169447422027588 train acc 0.8849132707165581\n",
            "epoch 1 batch id 6801 loss 0.4640122950077057 train acc 0.8861449602999559\n",
            "epoch 1 batch id 7001 loss 0.1656411588191986 train acc 0.8872661048421654\n",
            "epoch 1 batch id 7201 loss 0.35941818356513977 train acc 0.8882294993750868\n",
            "epoch 1 batch id 7401 loss 0.20273403823375702 train acc 0.889366724091339\n",
            "epoch 1 batch id 7601 loss 0.1901659369468689 train acc 0.8903495428233127\n",
            "epoch 1 batch id 7801 loss 0.35269951820373535 train acc 0.8912399051403667\n",
            "epoch 1 batch id 8001 loss 0.26661673188209534 train acc 0.8920701318585177\n",
            "epoch 1 batch id 8201 loss 0.175480455160141 train acc 0.8929303591025485\n",
            "epoch 1 batch id 8401 loss 0.28557199239730835 train acc 0.893775666587311\n",
            "epoch 1 batch id 8601 loss 0.25920137763023376 train acc 0.894479929659342\n",
            "epoch 1 batch id 8801 loss 0.5494610071182251 train acc 0.8951450829451199\n",
            "epoch 1 batch id 9001 loss 0.2744270861148834 train acc 0.8958015081657593\n",
            "epoch 1 batch id 9201 loss 0.3244454562664032 train acc 0.8963818470818389\n",
            "epoch 1 batch id 9401 loss 0.2832557260990143 train acc 0.8970338926709924\n",
            "epoch 1 batch id 9601 loss 0.36306703090667725 train acc 0.8976115769190709\n",
            "epoch 1 batch id 9801 loss 0.24367083609104156 train acc 0.8982374247525763\n",
            "epoch 1 batch id 10001 loss 0.30121856927871704 train acc 0.8988257424257574\n",
            "epoch 1 batch id 10201 loss 0.273966908454895 train acc 0.8993618885403392\n",
            "epoch 1 batch id 10401 loss 0.3335038423538208 train acc 0.8998939404864916\n",
            "epoch 1 batch id 10601 loss 0.10964111238718033 train acc 0.900394125554193\n",
            "epoch 1 batch id 10801 loss 0.3818100392818451 train acc 0.9008251550782335\n",
            "epoch 1 train acc 0.9010959498994332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4688 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a940bc5ee31741848a8ec702906e461d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 test acc 0.9277110441552902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "WfI2icC6POOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 불러오기\n",
        "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/model_0412_km_remove_model_2.pth'))"
      ],
      "metadata": {
        "id": "XGPK2y6LQK24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "submission_org =  pd.read_csv(\"/content/drive/MyDrive/통계데이터_인공지능_활용대회/답안 작성용 파일.csv\", encoding='euc-kr')"
      ],
      "metadata": {
        "id": "arTlksnuPhGO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_data = submission_org[['digit_3','text_obj','text_mthd','text_deal']]"
      ],
      "metadata": {
        "id": "mFaWMehRPeDL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_mod = df_mod.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
        "print(submission_data.isnull().values.any()) # Null 값이 존재하는지 확인\n",
        "submission_data = submission_data.fillna(' ') # Nan 값을 빈 string으로 바꿈\n",
        "print(submission_data.isnull().values.any()) # Null 값이 존재하는지 확인\n",
        "# False => nan값이 없다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97f4fc52-2524-41c7-959b-6989fce6182e",
        "id": "wfnajAgMPeDL"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data x, y 로 나누기\n",
        "sub_x1 = submission_data['text_obj'].astype(str)\n",
        "sub_x2 = submission_data['text_mthd'].astype(str)\n",
        "sub_x3 = submission_data['text_deal'].astype(str)"
      ],
      "metadata": {
        "id": "XDWXlwGWPeDM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_1 = ['에서','으로','에게','하여',] # text_obj, text_mthd,\n",
        "remove_2 =['일반','고객'] # text_mthd \n",
        "remove_3 = ['를 통하여','을 갖추고','를통하여'] #  text_mthd\n",
        "for i in range(len(sub_x1)):\n",
        "  # remove 1\n",
        "  if sub_x1.iloc[i][-2::]in remove_1: # text_obj\n",
        "    sub_x1[i]=sub_x1.iloc[i][0:-2]\n",
        "  \n",
        "  if sub_x2.iloc[i][-2::]in remove_1: # text_mthd\n",
        "    sub_x2[i]=sub_x2.iloc[i][0:-2]\n",
        "\n",
        "  # remove 2\n",
        "  if sub_x2.iloc[i][0:2]in remove_2:  # text_mthd\n",
        "    sub_x2[i]=' ' # remove_2 들어가면 제거 \n",
        "    \n",
        "  # remove 3\n",
        "  if sub_x2.iloc[i][-5::]in remove_3: # text_mthd\n",
        "    sub_x2[i]=sub_x2.iloc[i][0:-5]\n",
        "  \n",
        "  if sub_x2.iloc[i][-4::]in remove_3: # text_mthd\n",
        "    sub_x2[i]=sub_x2.iloc[i][0:-4]\n",
        "    \n",
        "  if i % 10000 == 0:\n",
        "    print(i)\n",
        "    \n",
        "    \n"
      ],
      "metadata": {
        "id": "yivPlWJ5PeDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_x = sub_x1 + ',' + sub_x2+','+ sub_x3"
      ],
      "metadata": {
        "id": "HEJlIUN1PeDN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmKJKNecP9-0",
        "outputId": "92ad88cb-c33f-445b-a51a-e09828b50450"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                      치킨전문점, ,치킨판매\n",
              "1             산업공구,다른 소매업자에게,철물 수공구\n",
              "2               절에서,신도을 대상으로,불교단체운영\n",
              "3                 영업장에서,고객요구로,자동차튜닝\n",
              "4        실내포장마차에서,접객시설을 갖추고,소주,맥주제공\n",
              "                    ...            \n",
              "99995            사업장에서,일반인대상으로,버섯농장\n",
              "99996              한의원에서,외래환자위주고,치료\n",
              "99997             일반점포에서,소비자에게,그림판매\n",
              "99998       사업장에서,일반인.학생대상으로,학습공간제공\n",
              "99999             사업장에서,대리현대아파트를,관리\n",
              "Length: 100000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_esu24FyGjKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = \"에서 로 으로 갖추고 일반 대상 . , 등 따라 의해 에 로 위하여 ? 통해 하여 에게 소비 제공 소비자 고객 일반인 을 를 의 하여 해서 요청 가지고 및 두고 받아 받음 서비스\"\n",
        "stop_words = set(stop_words.split(' '))\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh1Qd6Vi6KO9",
        "outputId": "5113a987-68e7-4d1e-b753-bfe163631279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'의', ',', '으로', '일반인', '에서', '및', '대상', '서비스', '받음', '받아', '갖추고', '하여', '에게', '따라', '일반', '요청', '통해', '위하여', '소비자', '소비', '고객', '두고', '가지고', '.', '을', '로', '에', '제공', '?', '를', '등', '의해', '해서'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()"
      ],
      "metadata": {
        "id": "oPYGUBYU6_q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = sub_x[0]\n",
        "word_tokens = okt.morphs(q)\n",
        "print(word_tokens)\n",
        "result = ' '\n",
        "for word in word_tokens:\n",
        "  if not word in stop_words:\n",
        "    result += ' ' + word\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrNzuxFK7DL1",
        "outputId": "483a0bde-2788-43a0-e861-34bc1b61996e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['치킨', '전문점', '에서', '치킨', '판매']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDcBI5apVh9e",
        "outputId": "17dff3d9-6d92-4d6f-f25b-55520fb2d8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  치킨 전문점 치킨 판매\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnt = 0\n",
        "for i in range(len(sub_x)):\n",
        "  q = sub_x[i]\n",
        "  word_tokens = okt.morphs(q)  \n",
        "  result = ' '\n",
        "  for word in word_tokens:\n",
        "    if not word in stop_words:\n",
        "      result += ' ' + word  \n",
        "  sub_x[i] = result\n",
        "  cnt += 1\n",
        "  if cnt%1000 == 0:\n",
        "    print(cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxDPkmR390bx",
        "outputId": "59721029-086c-4cc0-b86c-c1074887359c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "50000\n",
            "51000\n",
            "52000\n",
            "53000\n",
            "54000\n",
            "55000\n",
            "56000\n",
            "57000\n",
            "58000\n",
            "59000\n",
            "60000\n",
            "61000\n",
            "62000\n",
            "63000\n",
            "64000\n",
            "65000\n",
            "66000\n",
            "67000\n",
            "68000\n",
            "69000\n",
            "70000\n",
            "71000\n",
            "72000\n",
            "73000\n",
            "74000\n",
            "75000\n",
            "76000\n",
            "77000\n",
            "78000\n",
            "79000\n",
            "80000\n",
            "81000\n",
            "82000\n",
            "83000\n",
            "84000\n",
            "85000\n",
            "86000\n",
            "87000\n",
            "88000\n",
            "89000\n",
            "90000\n",
            "91000\n",
            "92000\n",
            "93000\n",
            "94000\n",
            "95000\n",
            "96000\n",
            "97000\n",
            "98000\n",
            "99000\n",
            "100000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "def predict(predict_sentence):\n",
        "    \n",
        "    data = [predict_sentence, '0']\n",
        "    dataset_another = [data]\n",
        "    \n",
        "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
        "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=2)\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "\n",
        "        \n",
        "        for i in out:\n",
        "            logits=i\n",
        "            \n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            \n",
        "            result = np.argmax(logits)\n",
        "            print(class_name[result])\n",
        "            test_eval.append(class_name[result])\n",
        "\n",
        "            return class_name[result]\n",
        "         \n",
        "\n"
      ],
      "metadata": {
        "id": "FLudU9XbQptH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_eval=[]\n",
        "idx = len(x)\n",
        "\n",
        "for i in range(idx):\n",
        "  predict(sub_x[i])\n",
        "  if i% 1000 == 0:\n",
        "\n",
        "     print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urS-wsFNqN7G",
        "outputId": "fead3abb-8c5b-4d36-8685-bb6f9347bdda"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "50000\n",
            "51000\n",
            "52000\n",
            "53000\n",
            "54000\n",
            "55000\n",
            "56000\n",
            "57000\n",
            "58000\n",
            "59000\n",
            "60000\n",
            "61000\n",
            "62000\n",
            "63000\n",
            "64000\n",
            "65000\n",
            "66000\n",
            "67000\n",
            "68000\n",
            "69000\n",
            "70000\n",
            "71000\n",
            "72000\n",
            "73000\n",
            "74000\n",
            "75000\n",
            "76000\n",
            "77000\n",
            "78000\n",
            "79000\n",
            "80000\n",
            "81000\n",
            "82000\n",
            "83000\n",
            "84000\n",
            "85000\n",
            "86000\n",
            "87000\n",
            "88000\n",
            "89000\n",
            "90000\n",
            "91000\n",
            "92000\n",
            "93000\n",
            "94000\n",
            "95000\n",
            "96000\n",
            "97000\n",
            "98000\n",
            "99000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search_big_middle(number):\n",
        "  class_big = ''\n",
        "\n",
        "  if number<51: class_big = 'A'\n",
        "  elif number<101: class_big = 'B'\n",
        "  elif number<351: class_big = 'C'\n",
        "  elif number<360: class_big = 'D'\n",
        "  elif number<411: class_big = 'E'\n",
        "  elif number<451: class_big = 'F'\n",
        "  elif number<491: class_big = 'G'\n",
        "  elif number<551: class_big = 'H'\n",
        "  elif number<581: class_big = 'I'\n",
        "  elif number<641: class_big = 'J'\n",
        "  elif number<681: class_big = 'K'\n",
        "  elif number<701: class_big = 'L'\n",
        "  elif number<741: class_big = 'M'\n",
        "  elif number<841: class_big = 'N'\n",
        "  elif number<851: class_big = 'O'\n",
        "  elif number<861: class_big = 'P'\n",
        "  elif number<901: class_big = 'Q'\n",
        "  elif number<941: class_big = 'R'\n",
        "  elif number<970: class_big = 'S'\n",
        "  elif number<990: class_big = 'T'\n",
        "  elif number<1000: class_big = 'U'\n",
        "  return class_big"
      ],
      "metadata": {
        "id": "SGwKb4uSdOcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#소분류 예측 (digit_3)\n",
        "submission_org['digit_3'] = test_eval  "
      ],
      "metadata": {
        "id": "1z6krSVeAxUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 중분류 예측 (digit_2)\n",
        "submission_org['digit_2'] = submission_org['digit_3']//10 "
      ],
      "metadata": {
        "id": "1K5X1S-gc_D5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 대분류 예측 (digit_1)\n",
        "for i in range(len(submission_org)):\n",
        "  submission_org['digit_1'][i] = search_big_middle(submission_org['digit_3'][i])\n",
        "  if i % 5000 == 0:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "ZsK8Xo5cdIrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_org.to_csv('제출용_파일.csv', index=False)"
      ],
      "metadata": {
        "id": "zD-K2Pc4Eo6i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}